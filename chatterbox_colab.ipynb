{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# 🎙️ Chatterbox TTS - Google Colab Demo\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/viveksurmay/chatterbox-colab/blob/master/chatterbox_colab.ipynb)\n",
    "\n",
    "Welcome to **Chatterbox TTS** by [Resemble AI](https://resemble.ai) - a state-of-the-art open-source text-to-speech model!\n",
    "\n",
    "## 🌟 Key Features\n",
    "- **Zero-shot TTS**: Generate speech in any voice with just a short audio sample\n",
    "- **Emotion Control**: Unique exaggeration/intensity control for expressive speech\n",
    "- **High Quality**: Outperforms many closed-source systems like ElevenLabs\n",
    "- **Voice Conversion**: Convert existing speech to different voices\n",
    "- **Watermarked**: Built-in Perth watermarking for responsible AI\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "installation"
   },
   "source": [
    "## 📦 Installation\n",
    "\n",
    "First, let's install Chatterbox TTS and its dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_chatterbox"
   },
   "outputs": [],
   "source": [
    "# Install Chatterbox TTS\n",
    "!pip install chatterbox-tts\n",
    "\n",
    "# Install additional dependencies for Colab\n",
    "!pip install ipywidgets\n",
    "\n",
    "print(\"✅ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 🚀 Setup and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_imports"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio as ta\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "import IPython.display as ipd\n",
    "from google.colab import files\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, Audio\n",
    "\n",
    "from chatterbox.tts import ChatterboxTTS\n",
    "from chatterbox.vc import ChatterboxVC\n",
    "\n",
    "print(\"📚 Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "device_setup"
   },
   "outputs": [],
   "source": [
    "# Automatically detect the best available device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(f\"🚀 Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    print(\"🍎 Using Apple Silicon MPS\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"💻 Using CPU (this will be slower)\")\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_model"
   },
   "outputs": [],
   "source": [
    "# Load the Chatterbox TTS model\n",
    "print(\"🔄 Loading Chatterbox TTS model... (this may take a few minutes)\")\n",
    "model = ChatterboxTTS.from_pretrained(device=device)\n",
    "print(\"✅ Model loaded successfully!\")\n",
    "print(f\"Sample rate: {model.sr} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "basic_tts"
   },
   "source": [
    "## 🎯 Basic Text-to-Speech Demo\n",
    "\n",
    "Let's start with a simple example using the default voice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "basic_demo"
   },
   "outputs": [],
   "source": [
    "# Example text\n",
    "text = \"Hello! Welcome to Chatterbox TTS. I'm excited to demonstrate high-quality text-to-speech synthesis with emotion control.\"\n",
    "\n",
    "print(f\"🎤 Generating speech for: '{text}'\")\n",
    "\n",
    "# Generate speech with default settings\n",
    "wav = model.generate(text)\n",
    "\n",
    "# Save and play the audio\n",
    "output_path = \"basic_demo.wav\"\n",
    "ta.save(output_path, wav, model.sr)\n",
    "\n",
    "print(\"✅ Audio generated!\")\n",
    "print(\"🔊 Click play to listen:\")\n",
    "ipd.display(ipd.Audio(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voice_cloning"
   },
   "source": [
    "## 🎭 Voice Cloning Demo\n",
    "\n",
    "Upload your own audio file to clone a voice! The audio should be:\n",
    "- Clear speech (no background noise)\n",
    "- At least 3-10 seconds long\n",
    "- WAV, MP3, or other common audio format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_audio"
   },
   "outputs": [],
   "source": [
    "# Upload audio file for voice cloning\n",
    "print(\"📁 Please upload an audio file for voice cloning:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    # Get the uploaded file name\n",
    "    audio_file = list(uploaded.keys())[0]\n",
    "    print(f\"✅ Uploaded: {audio_file}\")\n",
    "    \n",
    "    # Play the uploaded audio\n",
    "    print(\"🔊 Your uploaded audio:\")\n",
    "    ipd.display(ipd.Audio(audio_file))\n",
    "else:\n",
    "    print(\"❌ No file uploaded. Using default voice.\")\n",
    "    audio_file = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voice_clone_demo"
   },
   "outputs": [],
   "source": [
    "# Text for voice cloning demo\n",
    "clone_text = \"This is a demonstration of voice cloning using Chatterbox TTS. The model can replicate the voice characteristics from the uploaded audio sample.\"\n",
    "\n",
    "if audio_file:\n",
    "    print(f\"🎭 Cloning voice from '{audio_file}'...\")\n",
    "    print(f\"📝 Text: '{clone_text}'\")\n",
    "    \n",
    "    # Generate speech with the uploaded voice\n",
    "    cloned_wav = model.generate(\n",
    "        clone_text,\n",
    "        audio_prompt_path=audio_file,\n",
    "        exaggeration=0.5,\n",
    "        cfg_weight=0.5\n",
    "    )\n",
    "    \n",
    "    # Save and play the cloned audio\n",
    "    clone_output_path = \"voice_cloned.wav\"\n",
    "    ta.save(clone_output_path, cloned_wav, model.sr)\n",
    "    \n",
    "    print(\"✅ Voice cloning complete!\")\n",
    "    print(\"🔊 Cloned voice result:\")\n",
    "    ipd.display(ipd.Audio(clone_output_path))\n",
    "else:\n",
    "    print(\"⚠️ No audio file uploaded. Skipping voice cloning demo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "interactive_demo"
   },
   "source": [
    "## 🎛️ Interactive Demo with Advanced Controls\n",
    "\n",
    "Experiment with different parameters to control the speech generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "interactive_widgets"
   },
   "outputs": [],
   "source": [
    "# Create interactive widgets\n",
    "text_widget = widgets.Textarea(\n",
    "    value=\"The quick brown fox jumps over the lazy dog. This sentence contains every letter of the alphabet!\",\n",
    "    description=\"Text:\",\n",
    "    layout=widgets.Layout(width='100%', height='80px')\n",
    ")\n",
    "\n",
    "exaggeration_widget = widgets.FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0.25,\n",
    "    max=2.0,\n",
    "    step=0.05,\n",
    "    description=\"Exaggeration:\",\n",
    "    tooltip=\"Controls emotion intensity (0.5 = neutral, higher = more expressive)\"\n",
    ")\n",
    "\n",
    "cfg_weight_widget = widgets.FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.05,\n",
    "    description=\"CFG Weight:\",\n",
    "    tooltip=\"Controls pacing (lower = slower, more deliberate)\"\n",
    ")\n",
    "\n",
    "temperature_widget = widgets.FloatSlider(\n",
    "    value=0.8,\n",
    "    min=0.1,\n",
    "    max=2.0,\n",
    "    step=0.1,\n",
    "    description=\"Temperature:\",\n",
    "    tooltip=\"Controls randomness (lower = more consistent)\"\n",
    ")\n",
    "\n",
    "generate_button = widgets.Button(\n",
    "    description=\"🎤 Generate Speech\",\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# Display widgets\n",
    "display(text_widget)\n",
    "display(widgets.HBox([exaggeration_widget, cfg_weight_widget]))\n",
    "display(temperature_widget)\n",
    "display(generate_button)\n",
    "display(output_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "interactive_function"
   },
   "outputs": [],
   "source": [
    "# Interactive generation function\n",
    "def generate_interactive(button):\n",
    "    with output_widget:\n",
    "        output_widget.clear_output()\n",
    "        \n",
    "        text = text_widget.value.strip()\n",
    "        if not text:\n",
    "            print(\"❌ Please enter some text!\")\n",
    "            return\n",
    "        \n",
    "        print(f\"🎤 Generating speech...\")\n",
    "        print(f\"📝 Text: '{text[:50]}{'...' if len(text) > 50 else ''}'\")\n",
    "        print(f\"🎭 Exaggeration: {exaggeration_widget.value}\")\n",
    "        print(f\"⚡ CFG Weight: {cfg_weight_widget.value}\")\n",
    "        print(f\"🌡️ Temperature: {temperature_widget.value}\")\n",
    "        \n",
    "        try:\n",
    "            # Generate speech with custom parameters\n",
    "            wav = model.generate(\n",
    "                text,\n",
    "                audio_prompt_path=audio_file if 'audio_file' in globals() and audio_file else None,\n",
    "                exaggeration=exaggeration_widget.value,\n",
    "                cfg_weight=cfg_weight_widget.value,\n",
    "                temperature=temperature_widget.value\n",
    "            )\n",
    "            \n",
    "            # Save and play the audio\n",
    "            interactive_output_path = \"interactive_demo.wav\"\n",
    "            ta.save(interactive_output_path, wav, model.sr)\n",
    "            \n",
    "            print(\"✅ Generation complete!\")\n",
    "            print(\"🔊 Click play to listen:\")\n",
    "            ipd.display(ipd.Audio(interactive_output_path))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {str(e)}\")\n",
    "\n",
    "# Connect button to function\n",
    "generate_button.on_click(generate_interactive)\n",
    "\n",
    "print(\"🎛️ Interactive demo ready! Adjust the parameters above and click 'Generate Speech'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips_section"
   },
   "source": [
    "## 💡 Tips for Best Results\n",
    "\n",
    "### General Use (TTS and Voice Agents):\n",
    "- Default settings (`exaggeration=0.5`, `cfg_weight=0.5`) work well for most prompts\n",
    "- If the reference speaker has a fast speaking style, lower `cfg_weight` to around `0.3`\n",
    "\n",
    "### Expressive or Dramatic Speech:\n",
    "- Try lower `cfg_weight` values (e.g. `~0.3`) and increase `exaggeration` to around `0.7` or higher\n",
    "- Higher `exaggeration` tends to speed up speech; reducing `cfg_weight` helps compensate\n",
    "\n",
    "### Voice Cloning Tips:\n",
    "- Use clear, high-quality audio samples (3-10 seconds)\n",
    "- Avoid background noise or music\n",
    "- Single speaker recordings work best\n",
    "- The model works with various accents and languages (though optimized for English)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voice_conversion"
   },
   "source": [
    "## 🔄 Voice Conversion Demo\n",
    "\n",
    "Convert existing speech to a different voice using Chatterbox VC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_vc_model"
   },
   "outputs": [],
   "source": [
    "# Load the Voice Conversion model\n",
    "print(\"🔄 Loading Chatterbox VC model...\")\n",
    "vc_model = ChatterboxVC.from_pretrained(device=device)\n",
    "print(\"✅ Voice Conversion model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vc_demo"
   },
   "outputs": [],
   "source": [
    "# Voice conversion demo\n",
    "print(\"📁 Upload source audio (speech to convert):\")\n",
    "source_uploaded = files.upload()\n",
    "\n",
    "if source_uploaded:\n",
    "    source_audio = list(source_uploaded.keys())[0]\n",
    "    print(f\"✅ Source audio: {source_audio}\")\n",
    "    \n",
    "    print(\"🔊 Original audio:\")\n",
    "    ipd.display(ipd.Audio(source_audio))\n",
    "    \n",
    "    # Use the previously uploaded target voice or upload a new one\n",
    "    target_voice = audio_file if 'audio_file' in globals() and audio_file else None\n",
    "    \n",
    "    if not target_voice:\n",
    "        print(\"📁 Upload target voice (voice to convert to):\")\n",
    "        target_uploaded = files.upload()\n",
    "        if target_uploaded:\n",
    "            target_voice = list(target_uploaded.keys())[0]\n",
    "    \n",
    "    if target_voice:\n",
    "        print(f\"🎭 Converting '{source_audio}' to sound like '{target_voice}'...\")\n",
    "        \n",
    "        # Perform voice conversion\n",
    "        converted_wav = vc_model.generate(\n",
    "            source_audio,\n",
    "            target_voice_path=target_voice\n",
    "        )\n",
    "        \n",
    "        # Save and play the converted audio\n",
    "        vc_output_path = \"voice_converted.wav\"\n",
    "        ta.save(vc_output_path, converted_wav, vc_model.sr)\n",
    "        \n",
    "        print(\"✅ Voice conversion complete!\")\n",
    "        print(\"🔊 Converted audio:\")\n",
    "        ipd.display(ipd.Audio(vc_output_path))\n",
    "    else:\n",
    "        print(\"❌ No target voice provided. Skipping voice conversion.\")\n",
    "else:\n",
    "    print(\"❌ No source audio uploaded. Skipping voice conversion demo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "example_texts"
   },
   "source": [
    "## 📝 Example Texts to Try\n",
    "\n",
    "Here are some interesting texts to experiment with different voices and emotions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "example_texts_code"
   },
   "outputs": [],
   "source": [
    "# Example texts for different scenarios\n",
    "example_texts = {\n",
    "    \"Neutral Narration\": \"In a world where artificial intelligence meets human creativity, new possibilities emerge every day. Technology continues to reshape how we communicate and express ourselves.\",\n",
    "    \n",
    "    \"Excited Announcement\": \"Ladies and gentlemen, welcome to the most incredible show on Earth! Tonight, you'll witness amazing feats that will leave you speechless and wanting more!\",\n",
    "    \n",
    "    \"Dramatic Storytelling\": \"The storm raged through the night, lightning illuminating the dark castle on the hill. Inside, a mysterious figure waited by the window, watching for signs of dawn.\",\n",
    "    \n",
    "    \"Educational Content\": \"Today we'll learn about the fascinating world of machine learning. Neural networks process information much like the human brain, using interconnected nodes to recognize patterns.\",\n",
    "    \n",
    "    \"Gaming Commentary\": \"That was an absolutely incredible play! The team coordination was perfect, and that final move secured their victory in the championship match!\",\n",
    "    \n",
    "    \"Meditation Guide\": \"Take a deep breath and let your mind settle. Feel the tension leaving your body as you focus on the present moment. Peace and calm surround you.\"\n",
    "}\n",
    "\n",
    "print(\"📝 Example texts loaded! Copy any of these into the interactive demo above:\")\n",
    "print()\n",
    "\n",
    "for category, text in example_texts.items():\n",
    "    print(f\"**{category}:**\")\n",
    "    print(f'\"{text}\"')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_section"
   },
   "source": [
    "## 💾 Download Generated Audio\n",
    "\n",
    "Download your generated audio files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_files"
   },
   "outputs": [],
   "source": [
    "# Download generated audio files\n",
    "import os\n",
    "\n",
    "audio_files = [\n",
    "    \"basic_demo.wav\",\n",
    "    \"voice_cloned.wav\", \n",
    "    \"interactive_demo.wav\",\n",
    "    \"voice_converted.wav\"\n",
    "]\n",
    "\n",
    "print(\"💾 Available audio files for download:\")\n",
    "for file in audio_files:\n",
    "    if os.path.exists(file):\n",
    "        print(f\"✅ {file}\")\n",
    "        files.download(file)\n",
    "    else:\n",
    "        print(f\"❌ {file} (not generated yet)\")\n",
    "\n",
    "print(\"\\n📁 Files downloaded to your local machine!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "watermark_section"
   },
   "source": [
    "## 🔍 Watermark Detection\n",
    "\n",
    "All Chatterbox-generated audio includes Perth watermarks for responsible AI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "watermark_detection"
   },
   "outputs": [],
   "source": [
    "# Install Perth watermarker if not already installed\n",
    "!pip install resemble-perth\n",
    "\n",
    "import perth\n",
    "import librosa\n",
    "\n",
    "def check_watermark(audio_path):\n",
    "    \"\"\"Check if an audio file contains a Perth watermark\"\"\"\n",
    "    if not os.path.exists(audio_path):\n",
    "        return f\"❌ File {audio_path} not found\"\n",
    "    \n",
    "    try:\n",
    "        # Load the audio\n",
    "        watermarked_audio, sr = librosa.load(audio_path, sr=None)\n",
    "        \n",
    "        # Initialize watermarker\n",
    "        watermarker = perth.PerthImplicitWatermarker()\n",
    "        \n",
    "        # Extract watermark\n",
    "        watermark = watermarker.get_watermark(watermarked_audio, sample_rate=sr)\n",
    "        \n",
    "        if watermark > 0.5:\n",
    "            return f\"✅ {audio_path}: Watermarked (confidence: {watermark:.3f})\"\n",
    "        else:\n",
    "            return f\"❌ {audio_path}: No watermark detected (confidence: {watermark:.3f})\"\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error checking {audio_path}: {str(e)}\"\n",
    "\n",
    "print(\"🔍 Checking watermarks in generated audio files:\")\n",
    "print()\n",
    "\n",
    "for file in audio_files:\n",
    "    result = check_watermark(file)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## 🎉 Conclusion\n",
    "\n",
    "Congratulations! You've successfully used Chatterbox TTS in Google Colab. Here's what you've learned:\n",
    "\n",
    "✅ **Basic TTS**: Generate speech from text with the default voice  \n",
    "✅ **Voice Cloning**: Clone any voice from a short audio sample  \n",
    "✅ **Parameter Control**: Fine-tune exaggeration, pacing, and temperature  \n",
    "✅ **Voice Conversion**: Convert existing speech to different voices  \n",
    "✅ **Watermark Detection**: Verify responsible AI watermarking  \n",
    "\n",
    "### 🚀 Next Steps:\n",
    "- Try different voices and experiment with parameters\n",
    "- Use Chatterbox in your own projects via the Python API\n",
    "- Check out the [official repository](https://github.com/resemble-ai/chatterbox) for more examples\n",
    "- Join the [Discord community](https://discord.gg/rJq9cRJBJ6) for support and discussions\n",
    "\n",
    "### 📚 Resources:\n",
    "- [Chatterbox GitHub](https://github.com/resemble-ai/chatterbox)\n",
    "- [Resemble AI](https://resemble.ai)\n",
    "- [Demo Samples](https://resemble-ai.github.io/chatterbox_demopage/)\n",
    "- [Hugging Face Space](https://huggingface.co/spaces/ResembleAI/Chatterbox)\n",
    "\n",
    "---\n",
    "\n",
    "**Made with ♥️ by [Resemble AI](https://resemble.ai)**\n",
    "\n",
    "*Remember to use this technology responsibly and ethically!*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
