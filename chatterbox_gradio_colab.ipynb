{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üéôÔ∏è Chatterbox TTS - Gradio UI in Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/viveksurmay/chatterbox-colab/blob/master/chatterbox_gradio_colab.ipynb)\n",
    "\n",
    "**Simple Gradio interface for Chatterbox TTS without watermarking**\n",
    "\n",
    "## Features:\n",
    "- üé§ **Text-to-Speech** with voice cloning\n",
    "- üîÑ **Voice Conversion** \n",
    "- üö´ **No Watermarks** - Clean audio output\n",
    "- üéõÔ∏è **Simple Controls** - Easy to use interface\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üì¶ Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install gradio torch torchaudio librosa transformers diffusers safetensors numpy s3tokenizer conformer huggingface_hub\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "models"
   },
   "source": [
    "## ü§ñ Create No-Watermark Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_models"
   },
   "outputs": [],
   "source": [
    "# Create the no-watermark TTS class\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "# We'll create simplified versions inline for Colab\n",
    "print(\"üì¶ Setting up no-watermark models...\")\n",
    "\n",
    "# Import the original classes to modify them\n",
    "try:\n",
    "    from chatterbox.tts import ChatterboxTTS, punc_norm, Conditionals\n",
    "    from chatterbox.vc import ChatterboxVC\n",
    "    print(\"‚úÖ Chatterbox models imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Chatterbox not found, installing...\")\n",
    "    !pip install chatterbox-tts\n",
    "    from chatterbox.tts import ChatterboxTTS, punc_norm, Conditionals\n",
    "    from chatterbox.vc import ChatterboxVC\n",
    "    print(\"‚úÖ Chatterbox models imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "no_watermark_classes"
   },
   "outputs": [],
   "source": [
    "# Create no-watermark versions by monkey-patching\n",
    "class ChatterboxTTSNoWatermark(ChatterboxTTS):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Remove watermarker\n",
    "        self.watermarker = None\n",
    "    \n",
    "    def generate(self, *args, **kwargs):\n",
    "        # Call parent generate but intercept the watermarking\n",
    "        result = super().generate(*args, **kwargs)\n",
    "        # The parent method applies watermarking, but we'll return clean audio\n",
    "        # We need to override the generate method to skip watermarking\n",
    "        return self._generate_clean(*args, **kwargs)\n",
    "    \n",
    "    def _generate_clean(\n",
    "        self,\n",
    "        text,\n",
    "        repetition_penalty=1.2,\n",
    "        min_p=0.05,\n",
    "        top_p=1.0,\n",
    "        audio_prompt_path=None,\n",
    "        exaggeration=0.5,\n",
    "        cfg_weight=0.5,\n",
    "        temperature=0.8,\n",
    "    ):\n",
    "        if audio_prompt_path:\n",
    "            self.prepare_conditionals(audio_prompt_path, exaggeration=exaggeration)\n",
    "        else:\n",
    "            assert self.conds is not None, \"Please prepare_conditionals first or specify audio_prompt_path\"\n",
    "\n",
    "        # Update exaggeration if needed\n",
    "        if exaggeration != self.conds.t3.emotion_adv[0, 0, 0]:\n",
    "            from chatterbox.models.t3.modules.cond_enc import T3Cond\n",
    "            _cond = self.conds.t3\n",
    "            self.conds.t3 = T3Cond(\n",
    "                speaker_emb=_cond.speaker_emb,\n",
    "                cond_prompt_speech_tokens=_cond.cond_prompt_speech_tokens,\n",
    "                emotion_adv=exaggeration * torch.ones(1, 1, 1),\n",
    "            ).to(device=self.device)\n",
    "\n",
    "        # Norm and tokenize text\n",
    "        text = punc_norm(text)\n",
    "        text_tokens = self.tokenizer.text_to_tokens(text).to(self.device)\n",
    "\n",
    "        if cfg_weight > 0.0:\n",
    "            text_tokens = torch.cat([text_tokens, text_tokens], dim=0)\n",
    "\n",
    "        sot = self.t3.hp.start_text_token\n",
    "        eot = self.t3.hp.stop_text_token\n",
    "        text_tokens = F.pad(text_tokens, (1, 0), value=sot)\n",
    "        text_tokens = F.pad(text_tokens, (0, 1), value=eot)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            speech_tokens = self.t3.inference(\n",
    "                t3_cond=self.conds.t3,\n",
    "                text_tokens=text_tokens,\n",
    "                max_new_tokens=1000,\n",
    "                temperature=temperature,\n",
    "                cfg_weight=cfg_weight,\n",
    "                repetition_penalty=repetition_penalty,\n",
    "                min_p=min_p,\n",
    "                top_p=top_p,\n",
    "            )\n",
    "            speech_tokens = speech_tokens[0]\n",
    "\n",
    "            from chatterbox.models.s3tokenizer import drop_invalid_tokens\n",
    "            speech_tokens = drop_invalid_tokens(speech_tokens)\n",
    "            speech_tokens = speech_tokens[speech_tokens < 6561]\n",
    "            speech_tokens = speech_tokens.to(self.device)\n",
    "\n",
    "            wav, _ = self.s3gen.inference(\n",
    "                speech_tokens=speech_tokens,\n",
    "                ref_dict=self.conds.gen,\n",
    "            )\n",
    "            wav = wav.squeeze(0).detach().cpu().numpy()\n",
    "            # NO WATERMARKING - return clean audio\n",
    "        return torch.from_numpy(wav).unsqueeze(0)\n",
    "\n",
    "class ChatterboxVCNoWatermark(ChatterboxVC):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Remove watermarker\n",
    "        self.watermarker = None\n",
    "    \n",
    "    def generate(self, audio, target_voice_path=None):\n",
    "        if target_voice_path:\n",
    "            self.set_target_voice(target_voice_path)\n",
    "        else:\n",
    "            assert self.ref_dict is not None, \"Please prepare_conditionals first or specify target_voice_path\"\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            from chatterbox.models.s3tokenizer import S3_SR\n",
    "            audio_16, _ = librosa.load(audio, sr=S3_SR)\n",
    "            audio_16 = torch.from_numpy(audio_16).float().to(self.device)[None, ]\n",
    "\n",
    "            s3_tokens, _ = self.s3gen.tokenizer(audio_16)\n",
    "            wav, _ = self.s3gen.inference(\n",
    "                speech_tokens=s3_tokens,\n",
    "                ref_dict=self.ref_dict,\n",
    "            )\n",
    "            wav = wav.squeeze(0).detach().cpu().numpy()\n",
    "            # NO WATERMARKING - return clean audio\n",
    "        return torch.from_numpy(wav).unsqueeze(0)\n",
    "\n",
    "print(\"‚úÖ No-watermark classes created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gradio_ui"
   },
   "source": [
    "## üéõÔ∏è Launch Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gradio_app"
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Device detection\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üöÄ Using device: {DEVICE}\")\n",
    "\n",
    "# Global models\n",
    "tts_model = None\n",
    "vc_model = None\n",
    "\n",
    "def load_tts_model():\n",
    "    global tts_model\n",
    "    if tts_model is None:\n",
    "        print(\"üîÑ Loading TTS model...\")\n",
    "        tts_model = ChatterboxTTSNoWatermark.from_pretrained(DEVICE)\n",
    "        print(\"‚úÖ TTS model loaded!\")\n",
    "    return tts_model\n",
    "\n",
    "def load_vc_model():\n",
    "    global vc_model\n",
    "    if vc_model is None:\n",
    "        print(\"üîÑ Loading VC model...\")\n",
    "        vc_model = ChatterboxVCNoWatermark.from_pretrained(DEVICE)\n",
    "        print(\"‚úÖ VC model loaded!\")\n",
    "    return vc_model\n",
    "\n",
    "def generate_speech(text, audio_file, exaggeration, cfg_weight, temperature):\n",
    "    if not text.strip():\n",
    "        return None, \"‚ùå Please enter some text!\"\n",
    "    \n",
    "    try:\n",
    "        model = load_tts_model()\n",
    "        wav = model.generate(\n",
    "            text,\n",
    "            audio_prompt_path=audio_file,\n",
    "            exaggeration=exaggeration,\n",
    "            cfg_weight=cfg_weight,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        return (model.sr, wav.squeeze(0).numpy()), \"‚úÖ Speech generated successfully! (No watermark)\"\n",
    "    except Exception as e:\n",
    "        return None, f\"‚ùå Error: {str(e)}\"\n",
    "\n",
    "def convert_voice(source_audio, target_audio):\n",
    "    if source_audio is None or target_audio is None:\n",
    "        return None, \"‚ùå Please upload both source and target audio!\"\n",
    "    \n",
    "    try:\n",
    "        model = load_vc_model()\n",
    "        wav = model.generate(source_audio, target_voice_path=target_audio)\n",
    "        return (model.sr, wav.squeeze(0).numpy()), \"‚úÖ Voice converted successfully! (No watermark)\"\n",
    "    except Exception as e:\n",
    "        return None, f\"‚ùå Error: {str(e)}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "with gr.Blocks(title=\"üéôÔ∏è Chatterbox TTS - No Watermark\") as app:\n",
    "    gr.HTML(\"\"\"\n",
    "    <div style=\"text-align: center; margin-bottom: 20px;\">\n",
    "        <h1>üéôÔ∏è Chatterbox TTS</h1>\n",
    "        <p><strong>Simple Gradio Interface - No Watermarks Applied</strong></p>\n",
    "        <p><em>Running on: \"\"\" + DEVICE + \"\"\"</em></p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        with gr.Tab(\"üé§ Text-to-Speech\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    text_input = gr.Textbox(\n",
    "                        label=\"üìù Text to Synthesize\",\n",
    "                        placeholder=\"Enter your text here...\",\n",
    "                        lines=3,\n",
    "                        value=\"Hello! This is Chatterbox TTS generating speech without any watermarks.\"\n",
    "                    )\n",
    "                    audio_input = gr.Audio(\n",
    "                        label=\"üé≠ Reference Audio (Optional - for voice cloning)\",\n",
    "                        type=\"filepath\"\n",
    "                    )\n",
    "                    \n",
    "                    with gr.Row():\n",
    "                        exaggeration = gr.Slider(\n",
    "                            0.25, 2.0, value=0.5, step=0.05,\n",
    "                            label=\"üé≠ Exaggeration\",\n",
    "                            info=\"Emotion intensity (0.5=neutral)\"\n",
    "                        )\n",
    "                        cfg_weight = gr.Slider(\n",
    "                            0.0, 1.0, value=0.5, step=0.05,\n",
    "                            label=\"‚ö° CFG Weight\",\n",
    "                            info=\"Pacing control\"\n",
    "                        )\n",
    "                        temperature = gr.Slider(\n",
    "                            0.1, 2.0, value=0.8, step=0.1,\n",
    "                            label=\"üå°Ô∏è Temperature\",\n",
    "                            info=\"Randomness control\"\n",
    "                        )\n",
    "                    \n",
    "                    generate_btn = gr.Button(\"üé§ Generate Speech\", variant=\"primary\", size=\"lg\")\n",
    "                \n",
    "                with gr.Column():\n",
    "                    audio_output = gr.Audio(label=\"üîä Generated Audio\")\n",
    "                    status_output = gr.Textbox(label=\"Status\", interactive=False)\n",
    "        \n",
    "        with gr.Tab(\"üîÑ Voice Conversion\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    source_audio = gr.Audio(\n",
    "                        label=\"üìÅ Source Audio (speech to convert)\",\n",
    "                        type=\"filepath\"\n",
    "                    )\n",
    "                    target_audio = gr.Audio(\n",
    "                        label=\"üéØ Target Voice (voice to convert to)\",\n",
    "                        type=\"filepath\"\n",
    "                    )\n",
    "                    convert_btn = gr.Button(\"üîÑ Convert Voice\", variant=\"primary\", size=\"lg\")\n",
    "                \n",
    "                with gr.Column():\n",
    "                    converted_audio = gr.Audio(label=\"üîä Converted Audio\")\n",
    "                    vc_status = gr.Textbox(label=\"Status\", interactive=False)\n",
    "        \n",
    "        with gr.Tab(\"üí° Tips\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ## üí° Usage Tips\n",
    "            \n",
    "            ### üé§ Text-to-Speech:\n",
    "            - **Text**: Enter any text you want to synthesize\n",
    "            - **Reference Audio**: Upload 3-10 seconds of clear speech for voice cloning\n",
    "            - **Exaggeration**: 0.5=neutral, 0.7-1.0=expressive, 1.5+=dramatic\n",
    "            - **CFG Weight**: 0.3=slower, 0.5=balanced, 0.8+=faster\n",
    "            - **Temperature**: 0.5=consistent, 0.8=balanced, 1.5+=creative\n",
    "            \n",
    "            ### üîÑ Voice Conversion:\n",
    "            - Upload clear audio files for both source and target\n",
    "            - Keep audio samples between 3-15 seconds\n",
    "            - Similar speaking styles convert better\n",
    "            \n",
    "            ### ‚ú® Features:\n",
    "            - **No Watermarks**: All generated audio is clean\n",
    "            - **GPU Accelerated**: Faster generation when available\n",
    "            - **High Quality**: 24kHz sample rate output\n",
    "            \n",
    "            ---\n",
    "            **üéâ Enjoy creating amazing voices!**\n",
    "            \"\"\")\n",
    "    \n",
    "    # Event handlers\n",
    "    generate_btn.click(\n",
    "        fn=generate_speech,\n",
    "        inputs=[text_input, audio_input, exaggeration, cfg_weight, temperature],\n",
    "        outputs=[audio_output, status_output]\n",
    "    )\n",
    "    \n",
    "    convert_btn.click(\n",
    "        fn=convert_voice,\n",
    "        inputs=[source_audio, target_audio],\n",
    "        outputs=[converted_audio, vc_status]\n",
    "    )\n",
    "\n",
    "# Launch the app\n",
    "print(\"üöÄ Launching Gradio interface...\")\n",
    "app.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
